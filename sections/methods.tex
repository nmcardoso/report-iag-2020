\section{Materiais e Métodos}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% VISÃO GERAL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Visão Geral}

Pelo fluxograma da figura \ref{fig:fluxogram}, vemos que a primeira etapa no desenvolvimento da Rede Neural Convolucional é a aquisição e o pré-processamento dos dados. A criação da estrutura (sequência de camadas da rede neural) e o ajuste dos hiperparâmetros, também chamdo de \emph{fine tunning}, vem em seguida. É o treimento que une a primeira e a segunda etapa, pois é nele que os dados pré-processados são inseridos na estrutura modelada. Logo em seguida, é feita uma validação da rede treinada. É o desempenho da modelagem anterior que dá o \emph{feedback} das modificações necessárias para a próxima versão da estrutura. O desenvolvimento do modelo termina quando é atingida uma boa acurácia de predição.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{figures/dl_diagram.pdf}
  \caption{Fluxograma do desenvolvimento do modelo.}
  \label{fig:fluxogram}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% AQUISIÇÃO DOS DADOS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Aquisição dos dados}

Dados de treinamento são elementos fundamentais para o treinamento supervisionado de uma Rede Neural Artificial. Para treinar uma rede que aprenda a classificar galáxias de acordo com suas imagens é necessário fazê-la aprender formas e padrões das galáxias. Para isso, é necessário separar uma grande amostra de imagens de galáxias já classificadas por humanos.

A fonte dos dados são GalaxyZoo, que contém as classificações morfológicas, e os levantamentos SDSS e S-PLUS, que possuem as imagens das galáxias. A associação dos dados entre estas duas fontes são feitas pelas coordenadas do objeto no espaço.

As imagens do SDSS foram obtidas usando a \emph{API}\footnote{API: \emph{Application Programming Interface}. É uma interface de comicação entre sistemas.} do SDSS\footnote{Documentação da API: http://skyserver.sdss.org/dr16/en/help/docs/api.aspx.}. Já as imagens do S-PLUS foram obtidas pela contribuição dos algorítmos\footnote{Página do repositório: https://github.com/lucatelli/splus-tools.} de Geferson Lucatelli. A figura \ref{fig:galaxy_grid} é um exemplo das imagens RGB do SDSS.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{figures/galaxy_grid.jpg}
  \caption{Amostra com cinquenta imagens de galáxias (escala reduzida).}
  \label{fig:galaxy_grid}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% DIVISÃO DO CONJUNTO DE DADOS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Divisão do conjunto de dados}

O conjunto de dados é dividido em três subconjuntos: treinamento, validação e teste. Os dois primeiros são usados durante o treinamento, portanto, são com estes dados que a rede irá aprender, e o subjunto de teste é usado após o treinameto para verificar a generalidade da rede, ou seja, determinar se a rede consegue classificar uma imagem não vista antes.

Todos os modelos usam o mesmo conjunto de dados, para garantir que o desempenho de classificação do modelo não foi afetado pelos dados. Embora a fonte de dados seja diferente entre os modelos, imagens RGB do SDSS para alguns e fluxo de fótons do S-PLUS para outros, ambos os conjunto de dados tem exatamente os mesmos objetos em cada um dos subconjuntos.

Para cada subconjunto, é separada uma quantidade de amostras relativa à quantidade total de cada classe: 72\% para o treino, 18\% para a validação e 10\% para o teste. A tabela \ref{tab:img_qtd} mostra a quantidade de imagens para cada um dos subconjuntos conforme a classe.

\begin{table}[h!]
  \centering

  \caption{Quantidade de amostras de imagens de galáxias por classe.}
  \label{tab:img_qtd}

  \renewcommand{\arraystretch}{1.6}
  \begin{tabular}{ccccc}
    \toprule
    \thead{Classe} & \thead{Treinamento                       \\(72\%)} & \thead{Validação\\(18\%)} & \thead{Teste\\(10\%)} & \thead{Total} \\
    \midrule
    E              & 4.504              & 1.126 & 625 & 6.255 \\
    S              & 1.370              & 342   & 190 & 1.902 \\
    Total          & 5.874              & 1.468 & 815 & 8.157 \\
    \bottomrule
  \end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% PRÉ-PRECESSAMENTO DOS DADOS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pré-processamento dos dados}

O pré-processamento é a preparação das imagens para serem usadas pelo modelo, ou seja, é a transformação dos dados brutos em dados reconhecíveis pela rede. Isso envolve representar as imagens por  matrizes multidimensionais, onde cada elemento da matriz representa um pixel da imagem, e aplicar algumas transformações, especificadas a seguir. Todos os modelos usam imagens do tamanho 64x64 pixels.

Como as imagens do SDSS usadas estão no sistema de cor RGB, o tensor de entrada da rede terá dimensão (64, 64, 3). As primeiras duas dimensões são referentes ao comprimento e largura da imagem e a terceira aos três canais de cores RGB.

Já os dados do S-PLUS não foram processados e para o padrão de cor RGB e, portanto, informações de todas as 12 bandas fotométricas são usadas. Para que seja possível usar uma rede pré-treinada, a entrada é dividida em 4 tensores (64, 64, 3).

Todas as imagens são reescaladas para o intervalo [0, 1], dividindo cada elemento pelo valor máximo da imagem. Além disso, para as imagens do S-PLUS, a mediana da imagem é subtraída de cada pixel. Já que a mediana da imagem é uma aproximação do valor do céu.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% MODELAGEM DA REDE NEURAL ARTIFICIAL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Modelagem e Ajuste dos Hiperparâmetros}

A rede neural artificial foi programada em Python e a biblioteca Keras\footnote{Uma API de alto nível criada para modelagem e treinamento de redes neurais que, neste projeto, roda sobre o TensorFlow. Tem foco em permitir experimentação rápida.} foi usada para criar e treinar o modelo.

A modelagem é a criação de uma estrutura. Isto inclui: a escolha da quantidade de camadas, a definição do tipo de cada camada e a especificação da sequência em que as camadas aparecerão. Já os hiperparâmetros são os atributos de cada camada ou do modelo em geral. Alguns exemplos de hiperparâmetros são: a taxa de aprendizagem\footnote{A velocidade com que a rede neural aprende os padrões.} (\emph{learning rate}), a quantidade de unidades\footnote{A quantidade de neurônios artificais.} de cada camada e a taxa (\emph{rate}) das camadas \emph{dropout}. Estes ajustes são feitos empiricamente e reajustados de acordo com o resultado obtido após o treinamento, como visto na figura \ref{fig:fluxogram}.

Foram criados três modelos: o primeiro, usando apenas camadas convolucionais e \emph{pooling} ligadas a uma pequena rede densa (figura \ref{fig:conv_model}) o segundo, usando uma rede pré-treinada, VGG16, ligada a uma longa rede densa com \emph{dropout} (figura \ref{fig:pretrained_model}) e o terceiro, usando quatro tensores de entrada ligados a uma rede pré-treinada (figura \ref{fig:splus_model}).

\pagebreak
\begin{figure}[ht!]
  \centering
  \begin{minipage}[t]{.47\textwidth}
    \centering
    \input{figures/conv_model.tex}
    \captionof{figure}{\textbf{Modelo 1} -- Camadas convolucionais intercaladas com camadas \emph{pooling}.}
    \label{fig:conv_model}
  \end{minipage}%
  \hfill%
  \begin{minipage}[t]{.47\textwidth}
    \centering
    \input{figures/pretrained_model.tex}
    \captionof{figure}{\textbf{Modelo 2} -- Rede pré-treinada ligada à uma rede densa com \emph{dropout}.}
    \label{fig:pretrained_model}
  \end{minipage}
\end{figure}
\pagebreak

\begin{figure}[h!]
  \centering
  \input{figures/splus_model.tex}
  \caption{\textbf{Modelo 3} -- Três tensores de entrada ligados à rede pre-treinada.}
  \label{fig:splus_model}
\end{figure}

\pagebreak

Esta rede VGG16 é treinada usando a base de dados \emph{ImageNet}\footnote{http://www.image-net.org/.}, que possui milhões de imagens de objetos do cotidaino, mas não possui objetos do espaço. A idéia é descobrir que se usar uma rede pré-treinada com milhões de imagens, mas nenhuma de galáxias, é tão relevante quanto usar uma rede treinada com apenas alguns milhares de amostras, mas todas de galáxias. Pois as redes neurais convolucionais são usadas como camada de abstração do mundo visual, ou seja, elas detectam padrões como geometrias, texturas e cores.

% Para ambos os modelos, a dimensão do tensor da entrada é (200, 200, 3). Cinco unidades na camada de saída com ativador \texttt{Softmax}. A  função de perda utilizada foi a \texttt{Categorical Crossentropy} e o otimizador foi o \texttt{RMSprop}.

% \begin{table}[h!]
%   \centering
%   \begin{tabular}{cc}
%     \toprule
%     \thead{Hiperparâmetro}          & \thead{Valor}     \\
%     \midrule
%     Ativador (Conv2D)               & ReLu              \\
%     Ativador (Dense, 1)             & ReLu              \\
%     Unidades (Conv2D)               & 32, 64, 128 e 128 \\
%     Unidades (Dense, 1)             & 512               \\
%     Dimensão do Kernel (Conv2D)     & (3, 3)            \\
%     \emph{Pool Size} (MaxPooling2D) & (2, 2)            \\
%     Taxa de aprendizagem            & $10^{-4}$         \\
%     \bottomrule
%   \end{tabular}
%   \caption{Descrição dos hiperparâmetros do Modelo 1.}
%   \label{tab:hip_model1}
% \end{table}

% \begin{table}[h!]
%   \centering
%   \begin{tabular}{cc}
%     \toprule
%     \thead{Hiperparâmetro} & \thead{Valor}        \\
%     \midrule
%     Ativador (Dense, 1-4)  & ReLu                 \\
%     Unidades (Dense, 1-4)  & 2048, 1024, 512, 256 \\
%     Taxa de \emph{dropout} & 0,5                  \\
%     Taxa de aprendizagem   & $10^{-5}$            \\
%     \bottomrule
%   \end{tabular}
%   \caption{Descrição dos hiperparâmetros do Modelo 2.}
%   \label{tab:hip_model2}
% \end{table}

% Como mostrado na figura \ref{fig:fluxogram}, diversos valores de hiperparâmetros foram ajustados empiricamente. As tabelas \ref{tab:hip_model1} e \ref{tab:hip_model2} mostram os valores dos hiperparâmetros com melhor desempenho e que são usados como exemplo nos resultados.